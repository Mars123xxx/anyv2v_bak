{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This demo run AnyV2V(i2vgen-xl) pipeline on a single video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e449051358692d70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1. DDIM Inversion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c39a8064ee14977e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congwei/miniconda3/envs/anyv2v-i2vgen-xl/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/congwei/miniconda3/envs/anyv2v-i2vgen-xl/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/congwei/miniconda3/envs/anyv2v-i2vgen-xl/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# HF imports\n",
    "from diffusers import (\n",
    "    DDIMInverseScheduler,\n",
    "    DDIMScheduler,\n",
    ")\n",
    "from diffusers.utils import load_image, export_to_video, export_to_gif\n",
    "\n",
    "# Project imports\n",
    "from utils import (\n",
    "    seed_everything,\n",
    "    load_video_frames,\n",
    "    convert_video_to_frames,\n",
    "    load_ddim_latents_at_T,\n",
    "    load_ddim_latents_at_t,\n",
    ")\n",
    "from pipelines.pipeline_i2vgen_xl import I2VGenXLPipeline\n",
    "from run_group_ddim_inversion import ddim_inversion, ddim_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:22:28.993056Z",
     "start_time": "2024-03-23T03:22:25.339988Z"
    }
   },
   "id": "a72a44392afd4ea3",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up an example inversion config file\n",
    "config = {\n",
    "    # General\n",
    "    \"seed\": 8888,\n",
    "    \"device\": \"cuda:7\",  # <-- change this to the GPU you want to use\n",
    "    \"debug\": False,  # For logging DEBUG level messages otherwise INFO\n",
    "\n",
    "    # Dir\n",
    "    \"data_dir\": \"..\",  # <-- change this to the path of the data directory, if you cloned the repo, leave it as \"..\", the inversion latents will be saved in AnyV2V/inversions/\n",
    "    \"model_name\": \"i2vgen-xl\",\n",
    "    \"exp_name\": \"${video_name}\",\n",
    "    \"output_dir\": \"${data_dir}/inversions/${model_name}/${exp_name}\",\n",
    "\n",
    "    # Data\n",
    "    \"image_size\": [512, 512],\n",
    "    \"video_dir\": \"${data_dir}/demo\",\n",
    "    \"video_name\": \"An Old Man Doing Exercises For The Body And Mind\",\n",
    "    \"video_frames_path\": \"${video_dir}/${video_name}\",\n",
    "\n",
    "    # DDIM settings\n",
    "    \"n_frames\": 16,\n",
    "\n",
    "    # DDIM inversion\n",
    "    \"inverse_config\": {\n",
    "        \"image_size\": \"${image_size}\",\n",
    "        \"n_frames\": \"${n_frames}\",\n",
    "        \"cfg\": 1.0,\n",
    "        \"target_fps\": 8,\n",
    "        \"prompt\": \"\",\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"n_steps\": 10,\n",
    "        \"output_dir\": \"${output_dir}/ddim_latents\",\n",
    "    },\n",
    "\n",
    "    # DDIM reconstruction\n",
    "    \"recon_config\": {\n",
    "        \"enable_recon\": False,\n",
    "        \"image_size\": \"${image_size}\",\n",
    "        \"n_frames\": \"${n_frames}\",\n",
    "        \"cfg\": 9.0,\n",
    "        \"target_fps\": 8,\n",
    "        \"prompt\": \"\",\n",
    "        \"negative_prompt\": \"Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms\",\n",
    "        \"n_steps\": 50,\n",
    "        \"ddim_init_latents_t_idx\": 3,  # 0 for 981, 3 for 921, 9 for 801, 20 for 581 if n_steps=50\n",
    "        \"ddim_latents_path\": \"${inverse_config.output_dir}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the dictionary to an OmegaConf object\n",
    "config = OmegaConf.create(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:22:34.288619Z",
     "start_time": "2024-03-23T03:22:34.277826Z"
    }
   },
   "id": "10e80829f44153c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:23:20,184 - INFO - [<module>] - config: seed: 8888\n",
      "device: cuda:7\n",
      "debug: false\n",
      "data_dir: ..\n",
      "model_name: i2vgen-xl\n",
      "exp_name: ${video_name}\n",
      "output_dir: ${data_dir}/inversions/${model_name}/${exp_name}\n",
      "image_size:\n",
      "- 512\n",
      "- 512\n",
      "video_dir: ${data_dir}/demo\n",
      "video_name: An Old Man Doing Exercises For The Body And Mind\n",
      "video_frames_path: ${video_dir}/${video_name}\n",
      "n_frames: 16\n",
      "inverse_config:\n",
      "  image_size: ${image_size}\n",
      "  n_frames: ${n_frames}\n",
      "  cfg: 1.0\n",
      "  target_fps: 8\n",
      "  prompt: ''\n",
      "  negative_prompt: ''\n",
      "  n_steps: 10\n",
      "  output_dir: ${output_dir}/ddim_latents\n",
      "recon_config:\n",
      "  enable_recon: false\n",
      "  image_size: ${image_size}\n",
      "  n_frames: ${n_frames}\n",
      "  cfg: 9.0\n",
      "  target_fps: 8\n",
      "  prompt: ''\n",
      "  negative_prompt: Distorted, discontinuous, Ugly, blurry, low resolution, motionless,\n",
      "    static, disfigured, disconnected limbs, Ugly faces, incomplete arms\n",
      "  n_steps: 50\n",
      "  ddim_init_latents_t_idx: 3\n",
      "  ddim_latents_path: ${inverse_config.output_dir}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging_level = logging.DEBUG if config.debug else logging.INFO\n",
    "logging.basicConfig(level=logging_level, format=\"%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f\"config: {OmegaConf.to_yaml(config)}\")\n",
    "\n",
    "# Set up device and seed\n",
    "device = torch.device(config.device)\n",
    "torch.set_grad_enabled(False)\n",
    "seed_everything(config.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:23:20.189139Z",
     "start_time": "2024-03-23T03:23:20.180188Z"
    }
   },
   "id": "9774aa401544e91e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:23:22,297 - INFO - [<module>] - Loading frames from: ../demo/An Old Man Doing Exercises For The Body And Mind\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading frames from: {config.video_frames_path}\")\n",
    "_, frame_list = load_video_frames(config.video_frames_path, config.n_frames, config.image_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:23:22.728047Z",
     "start_time": "2024-03-23T03:23:22.290771Z"
    }
   },
   "id": "5f67a2e095eb5570",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c218c0f179f46af81b212b2ce1b6d0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'attention_head_dim': 64} were passed to I2VGenXLUNet, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "pipe = I2VGenXLPipeline.from_pretrained(\n",
    "        \"ali-vilab/i2vgen-xl\",\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    ")\n",
    "pipe.to(device)\n",
    "g = torch.Generator(device=device)\n",
    "g = g.manual_seed(config.seed)\n",
    "\n",
    "# Initialize the DDIM inverse scheduler\n",
    "inverse_scheduler = DDIMInverseScheduler.from_pretrained(\n",
    "        \"ali-vilab/i2vgen-xl\",\n",
    "        subfolder=\"scheduler\",\n",
    ")\n",
    "# Initialize the DDIM scheduler\n",
    "ddim_scheduler = DDIMScheduler.from_pretrained(\n",
    "        \"ali-vilab/i2vgen-xl\",\n",
    "        subfolder=\"scheduler\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:25:02.574245Z",
     "start_time": "2024-03-23T03:24:59.588227Z"
    }
   },
   "id": "6925d60c11d18672",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "first_frame = frame_list[0]  # Is a PIL image\n",
    "_ddim_latents = ddim_inversion(config.inverse_config, first_frame, frame_list, pipe, inverse_scheduler, g)\n",
    "# Reconstruction\n",
    "recon_config = config.recon_config\n",
    "if recon_config.enable_recon:\n",
    "            ddim_init_latents_t_idx = recon_config.ddim_init_latents_t_idx\n",
    "            ddim_scheduler.set_timesteps(recon_config.n_steps)\n",
    "            logger.info(f\"ddim_scheduler.timesteps: {ddim_scheduler.timesteps}\")\n",
    "            ddim_latents_path = recon_config.ddim_latents_path\n",
    "            ddim_latents_at_t = load_ddim_latents_at_t(\n",
    "                ddim_scheduler.timesteps[ddim_init_latents_t_idx],\n",
    "                ddim_latents_path=ddim_latents_path,\n",
    "            )\n",
    "            logger.debug(f\"ddim_scheduler.timesteps[t_idx]: {ddim_scheduler.timesteps[ddim_init_latents_t_idx]}\")\n",
    "            reconstructed_video = ddim_sampling(\n",
    "                recon_config,\n",
    "                first_frame,\n",
    "                ddim_latents_at_t,\n",
    "                pipe,\n",
    "                ddim_scheduler,\n",
    "                ddim_init_latents_t_idx,\n",
    "                g,\n",
    "            )\n",
    "\n",
    "            # Save the reconstructed video\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "            # Downsampling the video for space saving\n",
    "            reconstructed_video = [frame.resize((512, 512), resample=Image.LANCZOS) for frame in reconstructed_video]\n",
    "            export_to_video(\n",
    "                reconstructed_video,\n",
    "                os.path.join(config.output_dir, \"ddim_reconstruction.mp4\"),\n",
    "                fps=10,\n",
    "            )\n",
    "            export_to_gif(\n",
    "                reconstructed_video,\n",
    "                os.path.join(config.output_dir, \"ddim_reconstruction.gif\"),\n",
    "            )\n",
    "            logger.info(f\"Saved reconstructed video to {config.output_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae6748b7b5412306"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2. DDIM Sampling + PnP feature and attention injection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c10d1e7b830fb104"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# HF imports\n",
    "from diffusers import (\n",
    "    DDIMInverseScheduler,\n",
    "    DDIMScheduler,\n",
    ")\n",
    "from diffusers.utils import load_image, export_to_video, export_to_gif\n",
    "\n",
    "# Project imports\n",
    "from utils import (\n",
    "    seed_everything,\n",
    "    load_video_frames,\n",
    "    convert_video_to_frames,\n",
    "    load_ddim_latents_at_T,\n",
    "    load_ddim_latents_at_t,\n",
    ")\n",
    "from pipelines.pipeline_i2vgen_xl import I2VGenXLPipeline\n",
    "from pnp_utils import (\n",
    "    register_time,\n",
    "    register_conv_injection,\n",
    "    register_spatial_attention_pnp,\n",
    "    register_temp_attention_pnp,\n",
    ")\n",
    "\n",
    "from run_group_pnp_edit import init_pnp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:23:56.285990Z",
     "start_time": "2024-03-23T03:23:56.279956Z"
    }
   },
   "id": "d447c68aff374af5",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up an example sampling config file\n",
    "config = {\n",
    "    # General\n",
    "    \"seed\": 8888,\n",
    "    \"device\": \"cuda:4\",  # <-- change this to the GPU you want to use\n",
    "    \"debug\": False,  # For logging DEBUG level messages otherwise INFO\n",
    "\n",
    "    # Dir\n",
    "    \"data_dir\": \"..\",  # <-- change this to the path of the data directory, if you cloned the repo, leave it as \"..\", the inversion latents will be saved in AnyV2V/\n",
    "    \"model_name\": \"i2vgen-xl\",\n",
    "    \"task_name\": \"Prompt-Based-Editing\",\n",
    "    \"edited_video_name\": \"a robot doing exercises for the body and mind\",\n",
    "    \"output_dir\": \"${data_dir}/Results/${task_name}/${model_name}/${video_name}/${edited_video_name}/\",\n",
    "\n",
    "    # Data\n",
    "    \"image_size\": [512, 512],\n",
    "    \"video_dir\": \"${data_dir}/demo\",\n",
    "    \"video_name\":\"An Old Man Doing Exercises For The Body And Mind\",\n",
    "    \"video_frames_path\": \"${video_dir}/${video_name}\",\n",
    "    \"edited_first_frame_path\":\"${data_dir}/demo/An Old Man Doing Exercises For The Body And Mind/edited_first_frame/turn man into robot.png\",\n",
    "    \"ddim_latents_path\": \"${data_dir}/inversions/${model_name}/${video_name}/ddim_latents\",  # Same as inverse_config.output_dir\n",
    "\n",
    "    # Pnp Editing\n",
    "    \"n_frames\": 16,\n",
    "    \"cfg\": 9.0,\n",
    "    \"target_fps\": 8,\n",
    "    \"editing_prompt\":\"a man doing exercises for the body and mind\",\n",
    "    \"editing_negative_prompt\": \"Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms\",\n",
    "    \"n_steps\": 50,\n",
    "    \"ddim_init_latents_t_idx\": 0,  # 0 for 981, 3 for 921, 9 for 801, 20 for 581 if n_steps=50\n",
    "    \"ddim_inv_prompt\": \"\",\n",
    "    \"random_ratio\": 0.0,\n",
    "\n",
    "    # Pnp config\n",
    "    \"pnp_f_t\": 1.0,\n",
    "    \"pnp_spatial_attn_t\": 1.0,\n",
    "    \"pnp_temp_attn_t\":1.0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to an OmegaConf object\n",
    "config = OmegaConf.create(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:23:58.282613Z",
     "start_time": "2024-03-23T03:23:58.275938Z"
    }
   },
   "id": "e09b25b76823ff48",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:25:16,781 - INFO - [<module>] - config: seed: 8888\n",
      "device: cuda:4\n",
      "debug: false\n",
      "data_dir: ..\n",
      "model_name: i2vgen-xl\n",
      "task_name: Prompt-Based-Editing\n",
      "edited_video_name: a robot doing exercises for the body and mind\n",
      "output_dir: ${data_dir}/Results/${task_name}/${model_name}/${video_name}/${edited_video_name}/\n",
      "image_size:\n",
      "- 512\n",
      "- 512\n",
      "video_dir: ${data_dir}/demo\n",
      "video_name: An Old Man Doing Exercises For The Body And Mind\n",
      "video_frames_path: ${video_dir}/${video_name}\n",
      "edited_first_frame_path: ${data_dir}/demo/An Old Man Doing Exercises For The Body\n",
      "  And Mind/edited_first_frame/turn man into robot.png\n",
      "ddim_latents_path: ${data_dir}/inversions/${model_name}/${video_name}/ddim_latents\n",
      "n_frames: 16\n",
      "cfg: 9.0\n",
      "target_fps: 8\n",
      "editing_prompt: a man doing exercises for the body and mind\n",
      "editing_negative_prompt: Distorted, discontinuous, Ugly, blurry, low resolution, motionless,\n",
      "  static, disfigured, disconnected limbs, Ugly faces, incomplete arms\n",
      "n_steps: 50\n",
      "ddim_init_latents_t_idx: 0\n",
      "ddim_inv_prompt: ''\n",
      "random_ratio: 0.0\n",
      "pnp_f_t: 1.0\n",
      "pnp_spatial_attn_t: 1.0\n",
      "pnp_temp_attn_t: 1.0\n",
      "\n",
      "2024-03-22 23:25:16,848 - INFO - [<module>] - ddim_scheduler.timesteps: tensor([981, 961, 941, 921, 901, 881, 861, 841, 821, 801, 781, 761, 741, 721,\n",
      "        701, 681, 661, 641, 621, 601, 581, 561, 541, 521, 501, 481, 461, 441,\n",
      "        421, 401, 381, 361, 341, 321, 301, 281, 261, 241, 221, 201, 181, 161,\n",
      "        141, 121, 101,  81,  61,  41,  21,   1])\n",
      "2024-03-22 23:25:17,656 - INFO - [<module>] - Blending random_ratio (1 means random latent): 0.0\n",
      "2024-03-22 23:25:17,687 - INFO - [sample_with_pnp] - height: 512, width: 512\n",
      "2024-03-22 23:25:17,687 - INFO - [sample_with_pnp] - Prompt: a man doing exercises for the body and mind\n",
      "2024-03-22 23:25:19,558 - INFO - [sample_with_pnp] - self.scheduler: DDIMScheduler {\n",
      "  \"_class_name\": \"DDIMScheduler\",\n",
      "  \"_diffusers_version\": \"0.26.3\",\n",
      "  \"beta_end\": 0.02,\n",
      "  \"beta_schedule\": \"squaredcos_cap_v2\",\n",
      "  \"beta_start\": 0.0001,\n",
      "  \"clip_sample\": false,\n",
      "  \"clip_sample_range\": 1.0,\n",
      "  \"dynamic_thresholding_ratio\": 0.995,\n",
      "  \"num_train_timesteps\": 1000,\n",
      "  \"prediction_type\": \"v_prediction\",\n",
      "  \"rescale_betas_zero_snr\": true,\n",
      "  \"sample_max_value\": 1.0,\n",
      "  \"set_alpha_to_one\": true,\n",
      "  \"steps_offset\": 1,\n",
      "  \"thresholding\": false,\n",
      "  \"timestep_spacing\": \"leading\",\n",
      "  \"trained_betas\": null\n",
      "}\n",
      "\n",
      "2024-03-22 23:25:19,560 - INFO - [sample_with_pnp] - timesteps: tensor([981, 961, 941, 921, 901, 881, 861, 841, 821, 801, 781, 761, 741, 721,\n",
      "        701, 681, 661, 641, 621, 601, 581, 561, 541, 521, 501, 481, 461, 441,\n",
      "        421, 401, 381, 361, 341, 321, 301, 281, 261, 241, 221, 201, 181, 161,\n",
      "        141, 121, 101,  81,  61,  41,  21,   1], device='cuda:4')\n",
      "2024-03-22 23:25:19,561 - INFO - [sample_with_pnp] - Sampling starts from latents_at_t=981\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e9ec520528948ee81ecde9f7b9e94e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:26:26,085 - INFO - [<module>] - Saved video to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video.mp4\n",
      "2024-03-22 23:26:26,086 - INFO - [<module>] - Saved gif to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video.gif\n",
      "2024-03-22 23:26:26,182 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00000.png\n",
      "2024-03-22 23:26:26,277 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00001.png\n",
      "2024-03-22 23:26:26,372 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00002.png\n",
      "2024-03-22 23:26:26,468 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00003.png\n",
      "2024-03-22 23:26:26,564 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00004.png\n",
      "2024-03-22 23:26:26,661 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00005.png\n",
      "2024-03-22 23:26:26,756 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00006.png\n",
      "2024-03-22 23:26:26,852 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00007.png\n",
      "2024-03-22 23:26:26,948 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00008.png\n",
      "2024-03-22 23:26:27,042 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00009.png\n",
      "2024-03-22 23:26:27,137 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00010.png\n",
      "2024-03-22 23:26:27,231 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00011.png\n",
      "2024-03-22 23:26:27,361 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00012.png\n",
      "2024-03-22 23:26:27,473 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00013.png\n",
      "2024-03-22 23:26:27,569 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00014.png\n",
      "2024-03-22 23:26:27,666 - INFO - [<module>] - Saved frames to: ../Results/Prompt-Based-Editing/i2vgen-xl/An Old Man Doing Exercises For The Body And Mind/a robot doing exercises for the body and mind/ddim_init_latents_t_idx_0_nsteps_50_cfg_9.0_pnpf1.0_pnps1.0_pnpt1.0/video_00015.png\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging_level = logging.DEBUG if config.debug else logging.INFO\n",
    "logging.basicConfig(level=logging_level, format=\"%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f\"config: {OmegaConf.to_yaml(config)}\")\n",
    "\n",
    "# Set up device and seed\n",
    "device = torch.device(config.device)\n",
    "torch.set_grad_enabled(False)\n",
    "seed_everything(config.seed)\n",
    "\n",
    "\n",
    "src_frame_list = frame_list # Loaded from step 1\n",
    "src_1st_frame = src_frame_list[0]  # Is a PIL image\n",
    "\n",
    "# Load the edited first frame\n",
    "edited_1st_frame = load_image(config.edited_first_frame_path)\n",
    "edited_1st_frame = edited_1st_frame.resize(config.image_size, resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "# Load the initial latents at t\n",
    "ddim_init_latents_t_idx = config.ddim_init_latents_t_idx\n",
    "ddim_scheduler.set_timesteps(config.n_steps)\n",
    "logger.info(f\"ddim_scheduler.timesteps: {ddim_scheduler.timesteps}\")\n",
    "ddim_latents_at_t = load_ddim_latents_at_t(\n",
    "            ddim_scheduler.timesteps[ddim_init_latents_t_idx], ddim_latents_path=config.ddim_latents_path\n",
    "        )\n",
    "logger.debug(f\"ddim_scheduler.timesteps[t_idx]: {ddim_scheduler.timesteps[ddim_init_latents_t_idx]}\")\n",
    "logger.debug(f\"ddim_latents_at_t.shape: {ddim_latents_at_t.shape}\")\n",
    "\n",
    "# Blend the latents\n",
    "random_latents = torch.randn_like(ddim_latents_at_t)\n",
    "logger.info(f\"Blending random_ratio (1 means random latent): {config.random_ratio}\")\n",
    "mixed_latents = random_latents * config.random_ratio + ddim_latents_at_t * (1 - config.random_ratio)\n",
    "\n",
    "# Init Pnp\n",
    "init_pnp(pipe, ddim_scheduler, config)\n",
    "\n",
    "# Edit video\n",
    "pipe.register_modules(scheduler=ddim_scheduler)\n",
    "edited_video = pipe.sample_with_pnp(\n",
    "            prompt=config.editing_prompt,\n",
    "            image=edited_1st_frame,\n",
    "            height=config.image_size[1],\n",
    "            width=config.image_size[0],\n",
    "            num_frames=config.n_frames,\n",
    "            num_inference_steps=config.n_steps,\n",
    "            guidance_scale=config.cfg,\n",
    "            negative_prompt=config.editing_negative_prompt,\n",
    "            target_fps=config.target_fps,\n",
    "            latents=mixed_latents,\n",
    "            generator=torch.manual_seed(config.seed),\n",
    "            return_dict=True,\n",
    "            ddim_init_latents_t_idx=ddim_init_latents_t_idx,\n",
    "            ddim_inv_latents_path=config.ddim_latents_path,\n",
    "            ddim_inv_prompt=config.ddim_inv_prompt,\n",
    "            ddim_inv_1st_frame=src_1st_frame,\n",
    ").frames[0]\n",
    "\n",
    "# Save video\n",
    "# Add the config to the output_dir,\n",
    "config_suffix = (\n",
    "            \"ddim_init_latents_t_idx_\"\n",
    "            + str(ddim_init_latents_t_idx)\n",
    "            + \"_nsteps_\"\n",
    "            + str(config.n_steps)\n",
    "            + \"_cfg_\"\n",
    "            + str(config.cfg)\n",
    "            + \"_pnpf\"\n",
    "            + str(config.pnp_f_t)\n",
    "            + \"_pnps\"\n",
    "            + str(config.pnp_spatial_attn_t)\n",
    "            + \"_pnpt\"\n",
    "            + str(config.pnp_temp_attn_t)\n",
    ")\n",
    "output_dir = os.path.join(config.output_dir, config_suffix)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "edited_video = [frame.resize(config.image_size, resample=Image.LANCZOS) for frame in edited_video]\n",
    "edited_video_file_name = \"video\"\n",
    "export_to_video(edited_video, os.path.join(output_dir, f\"{edited_video_file_name}.mp4\"), fps=config.target_fps)\n",
    "export_to_gif(edited_video, os.path.join(output_dir, f\"{edited_video_file_name}.gif\"))\n",
    "logger.info(f\"Saved video to: {os.path.join(output_dir, f'{edited_video_file_name}.mp4')}\")\n",
    "logger.info(f\"Saved gif to: {os.path.join(output_dir, f'{edited_video_file_name}.gif')}\")\n",
    "for i, frame in enumerate(edited_video):\n",
    "      frame.save(os.path.join(output_dir, f\"{edited_video_file_name}_{i:05d}.png\"))\n",
    "      logger.info(f\"Saved frames to: {os.path.join(output_dir, f'{edited_video_file_name}_{i:05d}.png')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T03:26:27.669608Z",
     "start_time": "2024-03-23T03:25:16.762823Z"
    }
   },
   "id": "e5e5f5fa8e5eaeff",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
